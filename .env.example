# .env.example
LLM=ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral:7b
OLLAMA_TEMPERATURE=0.1
OLLAMA_NUM_PREDICT=768
OLLAMA_NUM_CTX=4096
OLLAMA_FORMAT=json
OLLAMA_TOP_P=0.9
OLLAMA_REPEAT_PENALTY=1.1